{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Red neuronal convolucional para el diagnóstico de nódulos tiroideos según la clasificación EU-TIRADS**\n",
    "\n",
    "## Por Alejandro Martínez Hernández\n",
    "\n",
    "### Notebook 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Procesamiento de datos**\n",
    "\n",
    "Ya conociendo la estructura de los datos, estos deben ser preparados y nuevamente organizados para poder usarlos en el entrenamiento de un modelo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creación de directorios**\n",
    "\n",
    "En la carpeta \"organized\" se crean otras carpetas para almacenar las imágenes (\\images) y anotaciones (\\notes) correspondientes que se van a usar para el entrenamiento.\n",
    "\n",
    "Dentro de estas carpetas habrán otras que contendrán las imágenes y anotaciones crudas (\\Raw) y otra para las imagenes y anotaciones ya procesadas (cropped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def crear_subcarpetas(carpeta_principal, subcarpetas, subcarpeta_padre=None):\n",
    "    \"\"\"\n",
    "    Crea subcarpetas dentro de una carpeta principal. Si se especifica una subcarpeta_padre,\n",
    "    las subcarpetas se crearán dentro de esta.\n",
    "    \n",
    "    Parámetros:\n",
    "    carpeta_principal (str): Ruta de la carpeta principal.\n",
    "    subcarpetas (list): Lista de nombres de subcarpetas a crear.\n",
    "    subcarpeta_padre (str): Nombre de la subcarpeta dentro de la cual se crearán nuevas subcarpetas.\n",
    "    \"\"\"\n",
    "    # Determinar la ruta base donde se crearán las subcarpetas\n",
    "    ruta_base = carpeta_principal if subcarpeta_padre is None else os.path.join(carpeta_principal, subcarpeta_padre)\n",
    "    \n",
    "    # Asegurar que la ruta base exista\n",
    "    if not os.path.exists(ruta_base):\n",
    "        os.makedirs(ruta_base)\n",
    "    \n",
    "    # Crear cada subcarpeta\n",
    "    for subcarpeta in subcarpetas:\n",
    "        os.makedirs(os.path.join(ruta_base, subcarpeta), exist_ok=True)\n",
    "\n",
    "# Aplicación de función\n",
    "carpeta_principal_1 = 'db_unal'\n",
    "carpeta_principal_2 = 'db_unal/organized'\n",
    "carpeta_principal_3 = 'db_unal/organized/images'\n",
    "carpeta_principal_4 = 'db_unal/organized/notes'\n",
    "\n",
    "subcarpetas_dentro_v1 = ['images', 'notes']  \n",
    "subcarpetas_dentro_v2 = ['raw', 'cropped'] \n",
    "subcarpetas_dentro_v3 = ['high', 'medium', 'low']   \n",
    "\n",
    "\n",
    "# Crear subcarpetas adicionales dentro de db_unal/organized\n",
    "crear_subcarpetas(carpeta_principal_1, subcarpetas_dentro_v1, 'organized')\n",
    "crear_subcarpetas(carpeta_principal_2, subcarpetas_dentro_v2, 'images')\n",
    "crear_subcarpetas(carpeta_principal_3, subcarpetas_dentro_v3, 'raw')\n",
    "crear_subcarpetas(carpeta_principal_3, subcarpetas_dentro_v3, 'cropped')\n",
    "crear_subcarpetas(carpeta_principal_4, subcarpetas_dentro_v3, 'raw')\n",
    "crear_subcarpetas(carpeta_principal_4, subcarpetas_dentro_v3, 'cropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importar los datos**\n",
    "\n",
    "Se trae el dataframe *df_agrupado.csv* que se generó en el notebook *1_exploracion_datos.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paciente</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Numero_imagen</th>\n",
       "      <th>TIRADS</th>\n",
       "      <th>Seg_radiologo_1</th>\n",
       "      <th>Seg_residente_1</th>\n",
       "      <th>Seg_residente_2</th>\n",
       "      <th>Composicion</th>\n",
       "      <th>Ecogenicidad</th>\n",
       "      <th>Margenes</th>\n",
       "      <th>Calcificaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_1</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_2</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2_1</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>solid</td>\n",
       "      <td>hyperechogenicity</td>\n",
       "      <td>well defined</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3_1</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spongiform</td>\n",
       "      <td>isoechogenicity</td>\n",
       "      <td>well defined</td>\n",
       "      <td>microcalcifications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4_1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spongiform</td>\n",
       "      <td>isoechogenicity</td>\n",
       "      <td>well defined</td>\n",
       "      <td>microcalcifications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146_1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147_1</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>148</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>148_1</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>solid</td>\n",
       "      <td>hypoechogenicity</td>\n",
       "      <td>well defined</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>149</td>\n",
       "      <td>78.0</td>\n",
       "      <td>M</td>\n",
       "      <td>149_1</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150_1</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paciente  Edad Sexo Numero_imagen  TIRADS  Seg_radiologo_1  \\\n",
       "0           1   NaN  NaN           1_1    high                1   \n",
       "1           1   NaN  NaN           1_2    high                1   \n",
       "2           2  49.0    F           2_1  medium                1   \n",
       "3           3  31.0    F           3_1  medium                1   \n",
       "4           4  37.0    F           4_1     low                1   \n",
       "..        ...   ...  ...           ...     ...              ...   \n",
       "167       146   NaN  NaN         146_1     low                1   \n",
       "168       147   NaN  NaN         147_1    high                1   \n",
       "169       148  37.0    F         148_1  medium                1   \n",
       "170       149  78.0    M         149_1    high                1   \n",
       "171       150   NaN  NaN         150_1     low                1   \n",
       "\n",
       "     Seg_residente_1  Seg_residente_2 Composicion       Ecogenicidad  \\\n",
       "0                  1                0         NaN                NaN   \n",
       "1                  1                1         NaN                NaN   \n",
       "2                  1                1       solid  hyperechogenicity   \n",
       "3                  1                1  spongiform    isoechogenicity   \n",
       "4                  1                1  spongiform    isoechogenicity   \n",
       "..               ...              ...         ...                ...   \n",
       "167                1                0         NaN                NaN   \n",
       "168                1                0         NaN                NaN   \n",
       "169                1                0       solid   hypoechogenicity   \n",
       "170                1                0         NaN                NaN   \n",
       "171                1                0         NaN                NaN   \n",
       "\n",
       "         Margenes      Calcificaciones  \n",
       "0             NaN                  NaN  \n",
       "1             NaN                  NaN  \n",
       "2    well defined                  NaN  \n",
       "3    well defined  microcalcifications  \n",
       "4    well defined  microcalcifications  \n",
       "..            ...                  ...  \n",
       "167           NaN                  NaN  \n",
       "168           NaN                  NaN  \n",
       "169  well defined                  NaN  \n",
       "170           NaN                  NaN  \n",
       "171           NaN                  NaN  \n",
       "\n",
       "[172 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def cargar_csv_de_forma_segura(ruta_archivo):\n",
    "    \"\"\"\n",
    "    Carga un archivo CSV en un DataFrame de pandas de manera segura.\n",
    "    \n",
    "    Parámetros:\n",
    "    ruta_archivo (str): La ruta completa al archivo CSV que se desea cargar.\n",
    "    \n",
    "    Retorna:\n",
    "    DataFrame: Un DataFrame de pandas con los datos cargados desde el archivo CSV.\n",
    "    None: Retorna None si ocurre un error durante la carga del archivo.\n",
    "    \"\"\"\n",
    "    # Verificar si el archivo existe\n",
    "    if not os.path.exists(ruta_archivo):\n",
    "        print(f\"El archivo {ruta_archivo} no existe.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Usar pandas para leer el archivo CSV\n",
    "        df = pd.read_csv(ruta_archivo)\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"El archivo está vacío.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error al parsear el archivo CSV.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar el archivo: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Cargar el archivo\n",
    "ruta_archivo = 'df_agrupado.csv'\n",
    "df_agrupado = cargar_csv_de_forma_segura(ruta_archivo)\n",
    "\n",
    "# Mostar dataframe\n",
    "df_agrupado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se importó la base de datos que indica que imágenes y anotaciones se van a usar, se generará una copia de cada uno de estos a las carpetas \\raw dentro de \\organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "ruta_origen = \"db_unal/originals/DDTI_V1\"\n",
    "ruta_destino_base = \"db_unal/organized/images/raw\"\n",
    "\n",
    "for index, row in df_agrupado.iterrows():\n",
    "    nombre_imagen = row['Numero_imagen'] + '.jpg'  # Asumiendo que los nombres en el DataFrame no incluyen '.jpg'\n",
    "    tirads_categoria = row['TIRADS'].lower()  # Asegurándonos de que el nombre del directorio esté en minúsculas\n",
    "\n",
    "    # Construir la ruta completa del archivo de origen\n",
    "    archivo_origen = os.path.join(ruta_origen, nombre_imagen)\n",
    "\n",
    "    # Construir la ruta completa del archivo de destino\n",
    "    ruta_destino = os.path.join(ruta_destino_base, tirads_categoria, nombre_imagen)\n",
    "\n",
    "    # Verificar si el archivo existe antes de intentar copiarlo\n",
    "    if os.path.exists(archivo_origen):\n",
    "        # Crear el directorio destino si no existe\n",
    "        os.makedirs(os.path.dirname(ruta_destino), exist_ok=True)\n",
    "        # Copiar el archivo\n",
    "        shutil.copy(archivo_origen, ruta_destino)\n",
    "    else:\n",
    "        print(f\"No se encontró el archivo {archivo_origen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para hacer recorte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir la ruta base del proyecto\n",
    "base_path = Path.cwd().parent\n",
    "\n",
    "# Funciones de ajuste de niveles y recorte de imagen\n",
    "def ajustar_niveles(imagen, nivel_min, nivel_max):\n",
    "    \"\"\"\n",
    "    Ajusta los niveles de la imagen utilizando cv2.normalize.\n",
    "    \"\"\"\n",
    "    return cv2.normalize(imagen, None, alpha=nivel_min, beta=nivel_max, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "def encontrar_y_recortar_imagen(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Encuentra la imagen de ultrasonido dentro de una captura de pantalla y la recorta\n",
    "    sin modificar el brillo y el contraste en la imagen recortada.\n",
    "    \"\"\"\n",
    "    # Leer la imagen original\n",
    "    imagen_original = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Convertir la imagen a escala de grises\n",
    "    imagen_gris = cv2.cvtColor(imagen_original, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ajustar los niveles de la imagen para mejorar el contraste\n",
    "    imagen_contrastada = ajustar_niveles(imagen_gris, 0, 255)\n",
    "    \n",
    "    # Umbralizar la imagen para obtener una binarización\n",
    "    _, imagen_binaria = cv2.threshold(imagen_contrastada, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Encontrar los contornos en la imagen binaria\n",
    "    contornos, _ = cv2.findContours(imagen_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Procesar cada contorno encontrado\n",
    "    for contorno in contornos:\n",
    "        # Calcular el rectángulo delimitador para el contorno\n",
    "        x, y, ancho, alto = cv2.boundingRect(contorno)\n",
    "        borde_mas_corto = min(ancho, alto)\n",
    "        borde_mas_largo = max(ancho, alto)\n",
    "        proporcion = borde_mas_largo / borde_mas_corto\n",
    "\n",
    "        # Comprobar si el contorno cumple con las condiciones de tamaño mínimo y proporción\n",
    "        if borde_mas_corto >= 250 and proporcion <= 1.5:\n",
    "            # Recortar la imagen original (sin ajustes de contraste) según el contorno que cumple con los requisitos\n",
    "            imagen_recortada = imagen_original[y:y+alto, x:x+ancho]\n",
    "            \n",
    "            # Guardar la imagen recortada\n",
    "            cv2.imwrite(output_path, imagen_recortada)\n",
    "            break  # Terminar después de procesar el primer contorno válido\n",
    "\n",
    "# Rutas de las carpetas de imágenes usando rutas relativas\n",
    "input_folder1 = 'db_unal/organized/images/raw'\n",
    "output_folder1 = 'db_unal/organized/images/cropped'\n",
    "\n",
    "# Función para procesar las imágenes\n",
    "def ubicar(input_folder, output_folder):\n",
    "    for filename in os.listdir(input_folder):\n",
    "        try:\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                input_path = input_folder / filename\n",
    "                base_name = filename.rsplit('.', 1)[0] + '.png'  # Cambiar la extensión a .png\n",
    "                output_path = output_folder / base_name\n",
    "                \n",
    "                try:\n",
    "                    encontrar_y_recortar_imagen(str(input_path), str(output_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo procesar el archivo {filename}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo procesar el archivo {filename}: {e}\")\n",
    "\n",
    "# Procesar imágenes\n",
    "ubicar(input_folder1, output_folder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para hacer undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Aumento de datos\n",
    "\n",
    "Dejaré este código para volver a usarlo en un futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Definir la ruta base del proyecto\n",
    "base_path = Path.cwd().parent\n",
    "\n",
    "# Ubicación de las imágenes ordenadas (usando pathlib para construir la ruta)\n",
    "database = base_path / 'data' / 'us_images' / 'procesadas' / 'ordenadas'\n",
    "\n",
    "# Instanciar ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.25,\n",
    "    height_shift_range=0.25,\n",
    "    shear_range=15,\n",
    "    zoom_range=[0.5, 1.5],\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Generadores para sets de entrenamiento y validación\n",
    "data_gen_entrenamiento = datagen.flow_from_directory(\n",
    "    database,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "data_gen_pruebas = datagen.flow_from_directory(\n",
    "    database,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Imprimir 10 imágenes del generador de entrenamiento\n",
    "for imagen, etiqueta in data_gen_entrenamiento:\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(imagen[i])\n",
    "    break\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
