{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Red neuronal convolucional para el diagnóstico de nódulos tiroideos según la clasificación EU-TIRADS**\n",
    "\n",
    "## Por Alejandro Martínez Hernández\n",
    "\n",
    "### Notebook 3/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creación de modelos**\n",
    "\n",
    "PAra la siguiente parte se crearan los siguientes modelos de clasificación simple:\n",
    "- SVM con crossvalidation y gridsearch para buscar parámetros.\n",
    "- SVM con preprocesamiento de datos con PCA, crossvalidation y gridsearch para buscar parámetros.\n",
    "- Forest con crossvalidation y gridsearch para buscar parámetros.\n",
    "- Forest con preprocesamiento de datos con PCA, crossvalidation y gridsearch para buscar parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Crossvalidation + GridSearch**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Mejor modelo: SVC(C=10)\n",
      "Mejor conjunto de parámetros: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mejor puntuación de validación cruzada: 0.6324369747899159\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ruta relativa a la carpeta que contiene las imágenes organizadas por etiquetas\n",
    "data_dir = \"db_unal/organized/images/cropped\"\n",
    "categories = ['high', 'low']\n",
    "\n",
    "# Listas para almacenar los datos de las imágenes y sus etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Cargar las imágenes y las etiquetas desde las carpetas\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is not None:\n",
    "            # Convertir imagen a escala de grises y redimensionar\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            # Aplanar la imagen para crear un vector de características\n",
    "            flattened_image = image.flatten()\n",
    "            data.append(flattened_image)\n",
    "            labels.append(category)\n",
    "\n",
    "# Convertir las listas de datos y etiquetas en arrays de numpy\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # valores de C\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.001],  # valores de gamma\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']  # tipos de kernel\n",
    "}\n",
    "\n",
    "# Crear el modelo SVM\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# Configuración de GridSearchCV\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Ejecutar GridSearch\n",
    "grid_search.fit(data, labels)\n",
    "\n",
    "# Mejor modelo y parámetros\n",
    "print(\"Mejor modelo:\", grid_search.best_estimator_)\n",
    "print(\"Mejor conjunto de parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PCA + Crossvalidation + GridSearch**\n",
    "\n",
    "En este código, se han modificado varias partes del anterior para incluir PCA:\n",
    "\n",
    "- **Pipeline de sklearn:** Utiliza Pipeline para encadenar PCA y SVM. Esto garantiza que PCA se aplique a los datos antes de que se pase a SVM en cada iteración del proceso de entrenamiento y validación cruzada.\n",
    "\n",
    "- **Parámetros de GridSearch:** Se actualizó param_grid para ajustarlo al pipeline, especificando que los parámetros se apliquen al estimador SVM dentro del pipeline (notado por el prefijo 'svm__' en los nombres de los parámetros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Mejor modelo: Pipeline(steps=[('pca', PCA(n_components=100)), ('svm', SVC(C=10))])\n",
      "Mejor conjunto de parámetros: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Mejor puntuación de validación cruzada: 0.6384873949579832\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ruta relativa a la carpeta que contiene las imágenes organizadas por etiquetas\n",
    "data_dir = \"db_unal/organized/images/cropped\"\n",
    "categories = ['high', 'low']\n",
    "\n",
    "# Listas para almacenar los datos de las imágenes y sus etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Cargar las imágenes y las etiquetas desde las carpetas\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is not None:\n",
    "            # Convertir imagen a escala de grises y redimensionar\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            # Aplanar la imagen para crear un vector de características\n",
    "            flattened_image = image.flatten()\n",
    "            data.append(flattened_image)\n",
    "            labels.append(category)\n",
    "\n",
    "# Convertir las listas de datos y etiquetas en arrays de numpy\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Definir el número de componentes para PCA\n",
    "n_components = 100  # Este valor puede ser ajustado según la varianza a conservar\n",
    "\n",
    "# Crear un pipeline que incluya PCA y SVM\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=n_components)),\n",
    "    ('svm', svm.SVC())\n",
    "])\n",
    "\n",
    "# Parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 0.001],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Ejecutar GridSearch\n",
    "grid_search.fit(data, labels)\n",
    "\n",
    "# Mejor modelo y parámetros\n",
    "print(\"Mejor modelo:\", grid_search.best_estimator_)\n",
    "print(\"Mejor conjunto de parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Crossvalidation + GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "240 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.5810084  0.64453782 0.52840336 0.63848739\n",
      " 0.55747899 0.60403361 0.54033613 0.63294118 0.53394958 0.65008403\n",
      " 0.57512605 0.62773109 0.57546218 0.63310924 0.58134454 0.65058824\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58722689 0.6389916  0.58672269 0.59193277\n",
      " 0.58689076 0.62672269 0.60403361 0.63831933 0.58672269 0.6507563\n",
      " 0.55142857 0.63310924 0.61697479 0.6502521  0.56991597 0.65042017\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.55210084 0.67378151 0.57546218 0.66218487\n",
      " 0.58655462 0.65042017 0.6097479  0.62756303 0.60487395 0.65042017\n",
      " 0.57512605 0.6210084  0.57546218 0.60386555 0.57512605 0.63932773\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.61042017 0.67327731 0.59277311 0.63294118\n",
      " 0.57495798 0.62134454 0.57008403 0.63815126 0.62705882 0.62117647\n",
      " 0.58756303 0.66823529 0.60941176 0.63277311 0.62773109 0.62689076\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58067227 0.65042017 0.5810084  0.61529412\n",
      " 0.53445378 0.66773109 0.59277311 0.65008403 0.55798319 0.64436975\n",
      " 0.66302521 0.69092437 0.62168067 0.65613445 0.62151261 0.63310924\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.54504202 0.63277311 0.6394958  0.61563025\n",
      " 0.62117647 0.63310924 0.6210084  0.63294118 0.59193277 0.67882353\n",
      " 0.61714286 0.65058824 0.59865546 0.68521008 0.56957983 0.63243697]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: RandomForestClassifier(bootstrap=False, max_depth=10, max_features='log2',\n",
      "                       min_samples_split=5)\n",
      "Mejor conjunto de parámetros: {'bootstrap': False, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mejor puntuación de validación cruzada: 0.6909243697478992\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ruta relativa a la carpeta que contiene las imágenes organizadas por etiquetas\n",
    "data_dir = \"db_unal/organized/images/cropped\"\n",
    "categories = ['high', 'low']\n",
    "\n",
    "# Listas para almacenar los datos de las imágenes y sus etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Cargar las imágenes y las etiquetas desde las carpetas\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is not None:\n",
    "            # Convertir imagen a escala de grises y redimensionar\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            # Aplanar la imagen para crear un vector de características\n",
    "            flattened_image = image.flatten()\n",
    "            data.append(flattened_image)\n",
    "            labels.append(category)\n",
    "\n",
    "# Convertir las listas de datos y etiquetas en arrays de numpy\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100],  # Número de árboles en el bosque\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Número de características a considerar al buscar la mejor división\n",
    "    'max_depth': [None, 10, 20],  # Profundidad máxima del árbol\n",
    "    'min_samples_split': [2, 5],  # Número mínimo de muestras requeridas para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2],  # Número mínimo de muestras requeridas en cada hoja del árbol\n",
    "    'bootstrap': [True, False]  # Método para muestrear puntos de datos (con o sin reemplazo)\n",
    "}\n",
    "\n",
    "# Crear el modelo de Random Forest\n",
    "forest_model = RandomForestClassifier()\n",
    "\n",
    "# Configuración de GridSearchCV\n",
    "grid_search = GridSearchCV(forest_model, param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Ejecutar GridSearch\n",
    "grid_search.fit(data, labels)\n",
    "\n",
    "# Mejor modelo y parámetros\n",
    "print(\"Mejor modelo:\", grid_search.best_estimator_)\n",
    "print(\"Mejor conjunto de parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PCA + Crossvalidation + GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "240 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\alema\\Desktop\\paper\\thyroid_nodules\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.58151261 0.57008403 0.52907563 0.56403361\n",
      " 0.59327731 0.58739496 0.53462185 0.56991597 0.5405042  0.55243697\n",
      " 0.5810084  0.58722689 0.61109244 0.58739496 0.54638655 0.54638655\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56352941 0.55260504 0.54655462 0.56420168\n",
      " 0.53411765 0.58151261 0.59882353 0.54689076 0.56352941 0.5410084\n",
      " 0.52857143 0.56386555 0.54689076 0.56403361 0.52352941 0.57579832\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.53478992 0.55260504 0.55310924 0.56991597\n",
      " 0.56470588 0.54655462 0.56369748 0.54672269 0.55260504 0.55210084\n",
      " 0.54722689 0.5697479  0.5810084  0.55815126 0.65680672 0.55260504\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.57008403 0.56436975 0.62756303 0.57563025\n",
      " 0.53529412 0.57579832 0.58151261 0.54655462 0.55210084 0.59831933\n",
      " 0.57008403 0.54067227 0.54067227 0.59260504 0.56420168 0.58117647\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.57579832 0.59882353 0.54655462 0.58117647\n",
      " 0.51142857 0.57008403 0.56941176 0.57563025 0.53495798 0.6102521\n",
      " 0.50672269 0.5989916  0.53478992 0.56369748 0.56941176 0.58168067\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.54588235 0.56957983 0.54689076 0.56386555\n",
      " 0.55882353 0.55243697 0.54084034 0.56403361 0.57529412 0.58722689\n",
      " 0.52352941 0.58134454 0.52336134 0.55226891 0.59865546 0.58117647]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Pipeline(steps=[('pca', PCA(n_components=100)),\n",
      "                ('forest',\n",
      "                 RandomForestClassifier(max_depth=20, max_features='log2',\n",
      "                                        min_samples_leaf=2, min_samples_split=5,\n",
      "                                        n_estimators=10))])\n",
      "Mejor conjunto de parámetros: {'forest__bootstrap': True, 'forest__max_depth': 20, 'forest__max_features': 'log2', 'forest__min_samples_leaf': 2, 'forest__min_samples_split': 5, 'forest__n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.6568067226890757\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ruta relativa a la carpeta que contiene las imágenes organizadas por etiquetas\n",
    "data_dir = \"db_unal/organized/images/cropped\"\n",
    "categories = ['high', 'low']\n",
    "\n",
    "# Listas para almacenar los datos de las imágenes y sus etiquetas\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Cargar las imágenes y las etiquetas desde las carpetas\n",
    "for category in categories:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is not None:\n",
    "            # Convertir imagen a escala de grises y redimensionar\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            # Aplanar la imagen para crear un vector de características\n",
    "            flattened_image = image.flatten()\n",
    "            data.append(flattened_image)\n",
    "            labels.append(category)\n",
    "\n",
    "# Convertir las listas de datos y etiquetas en arrays de numpy\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Definir el número de componentes principales para PCA\n",
    "n_components = 100\n",
    "\n",
    "# Crear un pipeline que incluya PCA y Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=n_components)),\n",
    "    ('forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'forest__n_estimators': [10, 100],\n",
    "    'forest__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'forest__max_depth': [None, 10, 20],\n",
    "    'forest__min_samples_split': [2, 5],\n",
    "    'forest__min_samples_leaf': [1, 2],\n",
    "    'forest__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Ejecutar GridSearch\n",
    "grid_search.fit(data, labels)\n",
    "\n",
    "# Mejor modelo y parámetros\n",
    "print(\"Mejor modelo:\", grid_search.best_estimator_)\n",
    "print(\"Mejor conjunto de parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Crossvalidation + GridSearch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PCA + Crossvalidation + GridSearch**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
